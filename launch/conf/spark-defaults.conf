# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
# spark.master                     spark://master:7077
# spark.eventLog.enabled           true
# spark.eventLog.dir               hdfs://namenode:8021/directory
# spark.serializer                 org.apache.spark.serializer.KryoSerializer
# spark.driver.memory              5g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"

# Application Properties
spark.app.name				parallel-boosting
spark.master				spark://hadoop33.rutgers.edu:7077
spark.executor.memory           	3g
spark.local.dir                 	/filer/tmp1/yw298/spark/tmp
spark.logConf				true
# Runtime Environment
spark.python.worker.memory              6g
spark.executorEnv.SPARK_HOME		/koko/system/linux/spark-1.1.0
spark.executorEnv.SPARK_LOG_DIR		/filer/tmp1/yw298/spark/log
spark.executorEnv.SPARK_WORK_DIR	/filer/tmp1/yw298/spark/work
spark.executorEnv.SPARK_TEMP_DIR	/filer/tmp1/yw298/spark/tmp
spark.executorEnv.SPARK_CONF_DIR	~/code/parallel-boosting/launch/conf
spark.executorEnv.PYTHONPATH		~/.local/bin:/usr/local/python_2.7
# Shuffle Behavior
spark.shuffle.consolidateFiles		true
spark.shuffle.memoryFraction            0.2
spark.shuffle.file.buffer.kb		128
spark.shuffle.manager			HASH
# Compression and Serialization
spark.io.compression.codec		lzf
# Scheduling
spark.task.cpus                         2
spark.task.maxFailures			8
spark.localExecution.enabled		false
spark.scheduler.revive.interval		2000
